[JTVAE]
hidden_size = 100
latent_size = 56
depthT = 20
depthG = 5

[PEAK_ENCODER]
max_mpz = 1000
embedding_size = 10
conv1_channel = 64
kernel1_width = 5
hidden_size = 200
num_rnn_layers = 2
bidirectional = False
output_size = 56
dropout_rate = 0.2
use_batchnorm=False

[TRAINING]
; Number of epoch to finish learning
max_epoch = 300
; Number of epoch to start learning the decoder
fine_tunning_warmup = 30

;*********************************************;
;  weight parameters
;  1. word                = word_rate
;  2. topology            = topo_rate
;  3. assemble            = assm_rate
;  4. KLDivergence        = beta
;  5. L2 regularization   = reg_rate
;
;  total loss =
;       word_rate * word_loss + 
;       topo_rate * topo_loss + 
;       assm_rate * assm_loss +
;       beta * kl_loss +
;       reg_rate * l2_reg
;*********************************************;
; weight of Word loss
word_rate = 1
; weight of topology loss
topo_rate = 1
; weight of assemble loss
assm_rate = 1
; weight of L2 regularization loss
reg_rate = 0.0

; Number of epoch to start appending step_beta to beta
warmup = 100
; Number of epoch 
kl_anneal_iter = 10
; Initial value of beta
init_beta = 0
; append value of beta
step_beta = 0.002
; max value of beta
max_beta = 1.0


anneal_rate = 1.0
anneal_iter = 10000

; interval of iteration to validation calculation.
;valid_interval = 1645 1 epoch = 329 iterations 
valid_interval = 3290
; interval of iteration to save model parameters
save_interval = 3290

